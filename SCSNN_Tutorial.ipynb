{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tn_wUlopkon"
      },
      "source": [
        "# Spiking Neural Network with SNNTorch\n",
        "This notebook demonstrates how to set up and train a spiking neural network using the SNNTorch library. We'll be using the MNIST dataset for this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tn_wUlopkon",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "!pip install snntorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXZ6Tuqc9Q-l"
      },
      "source": [
        "## Imports\n",
        "Import the necessary libraries for building and training the SNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXZ6Tuqc9Q-l"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import snntorch as snn\n",
        "from snntorch import surrogate\n",
        "from snntorch import backprop\n",
        "from snntorch import functional as SF\n",
        "from snntorch import utils\n",
        "from snntorch import spikeplot as splt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxO32dntlOB2"
      },
      "source": [
        "## Data Loading\n",
        "Define the dataloader arguments and set up the device to use for computations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxO32dntlOB2"
      },
      "outputs": [],
      "source": [
        "# dataloader arguments\n",
        "batch_size = 128\n",
        "data_path='/tmp/data/mnist'\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pE7eGTnulSBA"
      },
      "source": [
        "## Data Transformation and Loading\n",
        "Define a transform to resize and normalize the MNIST images, and create DataLoader objects for the training and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pE7eGTnulSBA"
      },
      "outputs": [],
      "source": [
        "# Define a transform\n",
        "transform = transforms.Compose([\n",
        "            transforms.Resize((28, 28)),\n",
        "            transforms.Grayscale(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0,), (1,))])\n",
        "\n",
        "mnist_train = datasets.MNIST(data_path, train=True, download=True, transform=transform)\n",
        "mnist_test = datasets.MNIST(data_path, train=False, download=True, transform=transform)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6v8fBXrVlY3f"
      },
      "source": [
        "## Define the Network\n",
        "The convolutional network architecture to be used is: 12C5-MP2-64C5-MP2-1024FC10\n",
        "- 12C5: 5x5 convolutional kernel with 12 filters\n",
        "- MP2: 2x2 max-pooling layer\n",
        "- 64C5: 5x5 convolutional kernel with 64 filters\n",
        "- MP2: 2x2 max-pooling layer\n",
        "- 1024FC10: Fully connected layer that maps 1024 neurons to 10 outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foos_NlopDrb"
      },
      "outputs": [],
      "source": [
        "# neuron and simulation parameters\n",
        "spike_grad = surrogate.fast_sigmoid(slope=25)\n",
        "beta = 0.5\n",
        "num_steps = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4sd8PDSlGZb"
      },
      "source": [
        "## Network Architecture\n",
        "Define the spiking neural network architecture using PyTorch modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4sd8PDSlGZb"
      },
      "outputs": [],
      "source": [
        "# Define Network\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Initialize layers\n",
        "        self.conv1 = nn.Conv2d(1, 12, 5)\n",
        "        self.lif1 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
        "        self.conv2 = nn.Conv2d(12, 64, 5)\n",
        "        self.lif2 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
        "        self.fc1 = nn.Linear(64*4*4, 10)\n",
        "        self.lif3 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Initialize hidden states and outputs at t=0\n",
        "        mem1 = self.lif1.init_leaky()\n",
        "        mem2 = self.lif2.init_leaky()\n",
        "        mem3 = self.lif3.init_leaky()\n",
        "\n",
        "        cur1 = F.max_pool2d(self.conv1(x), 2)\n",
        "        spk1, mem1 = self.lif1(cur1, mem1)\n",
        "\n",
        "        cur2 = F.max_pool2d(self.conv2(spk1), 2)\n",
        "        spk2, mem2 = self.lif2(cur2, mem2)\n",
        "\n",
        "        cur3 = self.fc1(spk2.view(batch_size, -1))\n",
        "        spk3, mem3 = self.lif3(cur3, mem3)\n",
        "        return spk3, mem3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoYBY89angvp"
      },
      "source": [
        "## Initialize the Network\n",
        "Set up the network with the defined layers and transfer it to the device (CPU/GPU)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AoYBY89angvp"
      },
      "outputs": [],
      "source": [
        "#  Initialize Network\n",
        "net = nn.Sequential(nn.Conv2d(1, 12, 5),\n",
        "                    nn.MaxPool2d(2),\n",
        "                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True),\n",
        "                    nn.Conv2d(12, 64, 5),\n",
        "                    nn.MaxPool2d(2),\n",
        "                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True),\n",
        "                    nn.Flatten(),\n",
        "                    nn.Linear(64*4*4, 10),\n",
        "                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True, output=True)\n",
        "                    ).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxPPMND-pMxE"
      },
      "source": [
        "## Forward Pass\n",
        "Perform a forward pass through the network to initialize the network and ensure the layers are correctly set up."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxPPMND-pMxE"
      },
      "outputs": [],
      "source": [
        "data, targets = next(iter(train_loader))\n",
        "data = data.to(device)\n",
        "targets = targets.to(device)\n",
        "\n",
        "for step in range(num_steps):\n",
        "    spk_out, mem_out = net(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykdnD3tRuHcs"
      },
      "source": [
        "## Forward Pass Function\n",
        "Define a function to perform the forward pass for a specified number of time steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykdnD3tRuHcs"
      },
      "outputs": [],
      "source": [
        "def forward_pass(net, num_steps, data):\n",
        "  mem_rec = []\n",
        "  spk_rec = []\n",
        "  utils.reset(net)  # resets hidden states for all LIF neurons in net\n",
        "\n",
        "  for step in range(num_steps):\n",
        "      spk_out, mem_out = net(data)\n",
        "      spk_rec.append(spk_out)\n",
        "      mem_rec.append(mem_out)\n",
        "\n",
        "  return torch.stack(spk_rec), torch.stack(mem_rec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZ2BM6d6a11l"
      },
      "source": [
        "## Loss Function\n",
        "Define the loss function to be used for training the SNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZ2BM6d6a11l"
      },
      "outputs": [],
      "source": [
        "# already imported snntorch.functional as SF\n",
        "loss_fn = SF.ce_rate_loss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqxDKFvrdXuF"
      },
      "source": [
        "## Batch Accuracy\n",
        "Define a function to compute the accuracy over the entire dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqxDKFvrdXuF"
      },
      "outputs": [],
      "source": [
        "def batch_accuracy(train_loader, net, num_steps):\n",
        "  with torch.no_grad():\n",
        "    total = 0\n",
        "    acc = 0\n",
        "    net.eval()\n",
        "\n",
        "    train_loader = iter(train_loader)\n",
        "    for data, targets in train_loader:\n",
        "      data = data.to(device)\n",
        "      targets = targets.to(device)\n",
        "      spk_rec, _ = forward_pass(net, num_steps, data)\n",
        "\n",
        "      acc += SF.accuracy_rate(spk_rec, targets) * spk_rec.size(1)\n",
        "      total += spk_rec.size(1)\n",
        "\n",
        "  return acc/total"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_u43hKAvefWM"
      },
      "source": [
        "## Evaluate Test Accuracy\n",
        "Compute the accuracy on the test set using the defined batch accuracy function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_u43hKAvefWM"
      },
      "outputs": [],
      "source": [
        "test_acc = batch_accuracy(test_loader, net, num_steps)\n",
        "\n",
        "print(f\"The total accuracy on the test set is: {test_acc * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_VQ9es-gSO3"
      },
      "source": [
        "## Training the Network\n",
        "Set up the optimizer and train the network over multiple epochs, tracking the loss and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_VQ9es-gSO3"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(net.parameters(), lr=1e-2, betas=(0.9, 0.999))\n",
        "num_epochs = 1\n",
        "loss_hist = []\n",
        "test_acc_hist = []\n",
        "counter = 0\n",
        "\n",
        "# Outer training loop\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # Training loop\n",
        "    for data, targets in iter(train_loader):\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # forward pass\n",
        "        net.train()\n",
        "        spk_rec, _ = forward_pass(net, num_steps, data)\n",
        "\n",
        "        # initialize the loss & sum over time\n",
        "        loss_val = loss_fn(spk_rec, targets)\n",
        "\n",
        "        # Gradient calculation + weight update\n",
        "        optimizer.zero_grad()\n",
        "        loss_val.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Store loss history for future plotting\n",
        "        loss_hist.append(loss_val.item())\n",
        "\n",
        "        # Test set\n",
        "        if counter % 50 == 0:\n",
        "          with torch.no_grad():\n",
        "              net.eval()\n",
        "\n",
        "              # Test set forward pass\n",
        "              test_acc = batch_accuracy(test_loader, net, num_steps)\n",
        "              print(f\"Iteration {counter}, Test Acc: {test_acc * 100:.2f}%\\n\")\n",
        "              test_acc_hist.append(test_acc.item())\n",
        "\n",
        "        counter += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Pk_EScnpkpj"
      },
      "source": [
        "## Plot Results\n",
        "Plot the accuracy on the test set over the training epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Pk_EScnpkpj",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Plot Loss\n",
        "fig = plt.figure(facecolor=\"w\")\n",
        "plt.plot(test_acc_hist)\n",
        "plt.title(\"Test Set Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "snntorch_tutorial_6.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "3.11.1 (v3.11.1:a7a450f84a, Dec  6 2022, 15:24:06) [Clang 13.0.0 (clang-1300.0.29.30)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
